MODEL_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=phi3:latest

# Para usar llama-cpp
LLAMA_CPP_MODEL_PATH=./models/Phi-3-mini-128k-instruct.gguf

# Para usar Transformers
TRANSFORMERS_MODEL_NAME=Phi-3-mini-128k-instruct

# RAG e dados
DATA_DIR=./data
STORAGE_DIR=./storage

# Integração Tainacan
TAINACAN_BASE_URL=https://seuwordpress.com
TAINACAN_COLLECTION_ID=123